{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk7JAW71bCEQ",
        "outputId": "b7f33f70-1348-4060-ea38-a3e56454a7db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz4vfARmn6DP"
      },
      "source": [
        "!mkdir -p corpus\n",
        "!cp /content/drive/MyDrive/machine-translation-data/Yandex/corpus.en_ru.1m.en ./corpus/\n",
        "!cp /content/drive/MyDrive/machine-translation-data/Yandex/corpus.en_ru.1m.ru ./corpus/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubJhFf5Uqrfg"
      },
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnEQ8PIAmIha"
      },
      "source": [
        "import tqdm\n",
        "import spacy\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Dataset, Example, Field, TabularDataset\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext.datasets import TranslationDataset\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp66_jw-mIhb",
        "outputId": "17e6d481-c5c5-4e92-f3e2-e5cb1ec6e159"
      },
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 2021\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s55gGqFoWbh"
      },
      "source": [
        "tokenizer_W = WordPunctTokenizer()\n",
        "def tokenize(x, tokenizer=tokenizer_W):\n",
        "    return tokenizer.tokenize(x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfbaqnV-mIhd"
      },
      "source": [
        "EN_TEXT = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)\n",
        "RU_TEXT = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjbfIn6YKvRC"
      },
      "source": [
        "dataset = TranslationDataset(\n",
        "    path='./corpus/corpus.en_ru.1m', exts=('.ru', '.en'),\n",
        "    fields=(RU_TEXT, EN_TEXT))\n",
        "train_data, valid_data = dataset.split(split_ratio=[0.98, 0.0, 0.02], random_state=random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u39bkRa2mIhe",
        "outputId": "1c573aa0-ce40-4a0d-a49c-4daec1941351"
      },
      "source": [
        "print(f'train set size: {len(train_data.examples):,}')\n",
        "print(f'valid set size: {len(valid_data.examples):,}')\n",
        "# print(f'test set size: {len(test_data.examples):,}')\n",
        "print(vars(train_data.examples[12412]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size: 980,000\n",
            "valid set size: 20,000\n",
            "{'src': ['надеюсь', ',', 'что', 'мой', 'любимый', 'университет', 'будет', 'и', 'дальше', 'развиваться', 'и', 'станет', 'одним', 'из', 'первых', 'в', 'мире', ',', 'потому', 'что', 'это', 'действительно', 'замечательный', 'университет', '.'], 'trg': ['i', 'hope', 'that', 'my', 'lovely', 'university', 'will', 'have', 'more', 'advancement', 'and', 'get', 'the', 'first', 'grade', 'in', 'the', 'world', ',', 'because', 'it', 'is', 'a', 'great', 'university', '!']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ned97r0M7M",
        "outputId": "291a9df1-9e4e-4d74-b9e0-876fa5b1efc9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 10 09:06:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELytCnwVmIhf"
      },
      "source": [
        "### Build vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GC-fOXSmIhf",
        "outputId": "cde6e3e8-d86d-4ff5-8a55-caebc0e2598e"
      },
      "source": [
        "%%time\n",
        "EN_MIN_COUNT = 2\n",
        "EN_TEXT.build_vocab(train_data, min_freq=EN_MIN_COUNT)\n",
        "RU_MIN_COUNT = 4\n",
        "RU_TEXT.build_vocab(train_data, min_freq=RU_MIN_COUNT)\n",
        "print(f'Length of EN vocabulary: {len(EN_TEXT.vocab):,}')\n",
        "print(f'Length of RU vocabulary: {len(RU_TEXT.vocab):,}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of EN vocabulary: 122,585\n",
            "Length of RU vocabulary: 174,852\n",
            "CPU times: user 18.9 s, sys: 844 ms, total: 19.7 s\n",
            "Wall time: 19.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kOFPHsLmIhg"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-JKljRgmIhg"
      },
      "source": [
        "### Multi Head Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbLJQzOSmIhg"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_size = d_model // n_heads\n",
        "        self.fc_q = nn.Linear(d_model, d_model)\n",
        "        self.fc_k = nn.Linear(d_model, d_model)\n",
        "        self.fc_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, q_len, d_model] query\n",
        "        :param Tensor[batch_size, k_len, d_model] key\n",
        "        :param Tensor[batch_size, v_len, d_model] value\n",
        "        :param Tensor[batch_size, ..., k_len] mask\n",
        "        :return Tensor[batch_size, q_len, d_model] context\n",
        "        :return Tensor[batch_size, n_heads, q_len, k_len] attention_weights\n",
        "        \"\"\"\n",
        "        Q = self.fc_q(query) # [batch_size, q_len, d_model]\n",
        "        K = self.fc_k(key) # [batch_size, k_len, d_model]\n",
        "        V = self.fc_v(value) # [batch_size, v_len, d_model]\n",
        "\n",
        "        Q = Q.view(Q.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, q_len, head_size]\n",
        "        K = K.view(K.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, k_len, head_size]\n",
        "        V = V.view(V.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, v_len, head_size]\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) # [batch_size, n_heads, q_len, k_len]\n",
        "        scores = scores / torch.sqrt(torch.FloatTensor([self.head_size]).to(Q.device))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e18)\n",
        "        attention_weights = F.softmax(scores , dim=-1) # [batch_size, n_heads, q_len, k_len]                \n",
        "        \n",
        "        context = torch.matmul(attention_weights, V) # [batch_size, n_heads, q_len, v_len]\n",
        "        context = context.permute(0, 2, 1, 3).contiguous() # [batch_size, q_len, n_heads, v_len]\n",
        "        context = context.view(context.size(0), -1, self.d_model)\n",
        "        context = self.fc_o(context) # [batch_size, q_len, d_model]\n",
        "\n",
        "        return context, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3PvGh5OmIhh"
      },
      "source": [
        "### Position-Wise Feed-Forward Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn4tkXL-mIhi"
      },
      "source": [
        "class PositionWiseFeedForwardLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, hidden_size):\n",
        "        super(PositionWiseFeedForwardLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.fc_in = nn.Linear(d_model, hidden_size)\n",
        "        self.fc_ou = nn.Linear(hidden_size, d_model)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len, d_model] inputs\n",
        "        :return Tensor[batch_size, seq_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        outputs = F.relu(self.fc_in(inputs)) # [batch_size, seq_len, hidden_size]\n",
        "        return self.fc_ou(outputs) # [batch_size, seq_len, d_model]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vzOPa-DmIhi"
      },
      "source": [
        "### Positional Encoding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efrbyw8hmIhi"
      },
      "source": [
        "class PositionalEncodingLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super(PositionalEncodingLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def get_angles(self, positions, indexes):\n",
        "        d_model_tensor = torch.FloatTensor([[self.d_model]]).to(positions.device)\n",
        "        angle_rates = torch.pow(10000, (2 * (indexes // 2)) / d_model_tensor)\n",
        "        return positions / angle_rates\n",
        "\n",
        "    def forward(self, input_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len] input_sequences\n",
        "        :return Tensor[batch_size, seq_len, d_model] position_encoding\n",
        "        \"\"\"\n",
        "        positions = torch.arange(input_sequences.size(1)).unsqueeze(1).to(input_sequences.device) # [seq_len, 1]\n",
        "        indexes = torch.arange(self.d_model).unsqueeze(0).to(input_sequences.device) # [1, d_model]\n",
        "        angles = self.get_angles(positions, indexes) # [seq_len, d_model]\n",
        "        angles[:, 0::2] = torch.sin(angles[:, 0::2]) # apply sin to even indices in the tensor; 2i\n",
        "        angles[:, 1::2] = torch.cos(angles[:, 1::2]) # apply cos to odd indices in the tensor; 2i\n",
        "        position_encoding = angles.unsqueeze(0).repeat(input_sequences.size(0), 1, 1) # [batch_size, seq_len, d_model]\n",
        "        return position_encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJlGFrLpmIhj"
      },
      "source": [
        "### Encoder Block Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWGGlGPNmIhj"
      },
      "source": [
        "class EncoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(EncoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, src_inputs, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len, d_model] src_inputs\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        context, _ = self.multi_head_attention_layer(query=src_inputs, key=src_inputs, value=src_inputs, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + src_inputs)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdtTnRsTmIhk"
      },
      "source": [
        "### Decoder Block Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPAhQkNmIhl"
      },
      "source": [
        "class DecoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(DecoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.mask_multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.mask_multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, dest_inputs, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_inputs\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size,  dest_len] dest_mask\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, dest_len, d_model] outputs\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        masked_context, _ = self.mask_multi_head_attention_layer(query=dest_inputs, key=dest_inputs, value=dest_inputs, mask=dest_mask)\n",
        "        masked_context = self.mask_multi_head_attention_layer_norm(self.dropout(masked_context) + dest_inputs)\n",
        "        \n",
        "        context, attention_weights = self.multi_head_attention_layer(query=masked_context, key=src_encoded, value=src_encoded, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + masked_context)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DJtsaCmIhm"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RdteY-umIhm"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.encoder_block_layers = nn.ModuleList([EncoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size,\n",
        "                                                                     dropout=dropout) for _ in range(n_layers)])\n",
        "    \n",
        "    def forward(self, src_sequences, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        position_encoded = self.position_encoding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, src_len, d_model]\n",
        "        for layer in self.encoder_block_layers:\n",
        "            outputs = layer(src_inputs=outputs, src_mask=src_mask) # [batch_size, src_len, d_model]\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi-q_IdhmIhn"
      },
      "source": [
        "### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6w3D0ufmIhn"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.decoder_block_layers = nn.ModuleList([DecoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size, dropout=dropout) for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "    \n",
        "    def forward(self, dest_sequences, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_mask\n",
        "        :param Tensor[batch_size, src_len, d_model] src_mask\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        position_encoded = self.position_encoding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, dest_len, d_model]\n",
        "        for layer in self.decoder_block_layers:\n",
        "            outputs, attention_weights = layer(dest_inputs=outputs, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        logits = self.fc(outputs)\n",
        "        return logits, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFwaKFGmIho"
      },
      "source": [
        "### Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUIswgvmIho"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, src_pad_index, dest_pad_index):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_index = src_pad_index\n",
        "        self.dest_pad_index = dest_pad_index\n",
        "\n",
        "    def make_src_mask(self, src_sequences):\n",
        "        \"\"\"Mask <pad> tokens.\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :return Tensor[batch size, 1, 1, src len] src_mask\n",
        "        \"\"\"        \n",
        "        src_mask = (src_sequences != self.src_pad_index).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "    \n",
        "    def make_dest_mask(self, dest_sequences):\n",
        "        \"\"\"Mask <pad> tokens and futur tokens as well.\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return tensor[batch_size, 1, dest_len, dest_len] dest_mask\n",
        "        \"\"\"\n",
        "        mask = (dest_sequences != self.dest_pad_index).unsqueeze(1).unsqueeze(2) # [batch size, 1, 1, trg len]\n",
        "        sub_mask = torch.tril(torch.ones((dest_sequences.size(1), dest_sequences.size(1))).to(dest_sequences.device)).bool() # [trg len, trg len]        \n",
        "        return mask & sub_mask\n",
        "    \n",
        "    def forward(self, src_sequences, dest_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        src_mask, dest_mask = self.make_src_mask(src_sequences), self.make_dest_mask(dest_sequences)\n",
        "        src_encoded = self.encoder(src_sequences=src_sequences, src_mask=src_mask)\n",
        "        logits, attention_weights = self.decoder(dest_sequences=dest_sequences, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        return logits, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZhcsU8YmIho"
      },
      "source": [
        "### Training routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u675PFn0mIho"
      },
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqR1OqZ3mIhp"
      },
      "source": [
        "def accuracy(outputs, target_sequences, k=5):\n",
        "    \"\"\" Calculate Top-k accuracy\n",
        "    :param Tensor[batch_size, dest_seq_len, vocab_size] outputs\n",
        "    :param Tensor[batch_size, dest_seq_len] target_sequences\n",
        "    :return float Top-k accuracy\n",
        "    \"\"\"\n",
        "    # print([*map(lambda token: EN.vocab.itos[token], outputs.argmax(dim=-1)[0].tolist())])\n",
        "    # print([*map(lambda token: EN.vocab.itos[token], target_sequences[0].tolist())])\n",
        "    # print(\"=\"*100)\n",
        "    batch_size = target_sequences.size(0)\n",
        "    _, indices = outputs.topk(k, dim=2, largest=True, sorted=True) # [batch_size, dest_seq_len, 5]\n",
        "    correct = indices.eq(target_sequences.unsqueeze(-1).expand_as(indices))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / indices.numel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esOC3Ki8mIhp"
      },
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, scheduler, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.scheduler = scheduler\n",
        "    \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            if i+1 >= 6251 and i+1 <= 6253:\n",
        "                continue\n",
        "            src, trg = batch.src, batch.trg\n",
        "            self.optimizer.zero_grad()\n",
        "            logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "            loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.detach().item())\n",
        "            acc_tracker.update(accuracy(logits.detach(), trg[:, 1:].detach()))\n",
        "            loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_:.3f} -     ppl: {ppl_:.3f} -     acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                src, trg = batch.src, batch.trg\n",
        "                logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "                loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "                loss_tracker.update(loss.detach().item())\n",
        "                acc_tracker.update(accuracy(logits.detach(), trg[:, 1:].detach()))\n",
        "                loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_:.3f} - val_ppl: {ppl_:.3f} - val_acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        best_loss = np.inf\n",
        "        for epoch in range(n_epochs):\n",
        "            loss, ppl, acc = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, val_ppl, val_acc = self.validate(valid_loader, epoch)\n",
        "            self.scheduler.step(val_loss)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './models/transformer.pth')\n",
        "        return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLK2C_OmIhp"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuNSZZ-YmIhp"
      },
      "source": [
        "D_MODEL = 256\n",
        "N_LAYERS = 6\n",
        "N_HEADS = 8\n",
        "HIDDEN_SIZE = 256\n",
        "MAX_LEN = 32\n",
        "DROPOUT = 0.05\n",
        "BATCH_SIZE = 32\n",
        "LR = 5e-4\n",
        "N_EPOCHS = 5\n",
        "GRAD_CLIP = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XimRFwZtmIhp",
        "outputId": "119aeee4-d340-403f-b928-369ed16c7306"
      },
      "source": [
        "transformer = Transformer(\n",
        "    encoder=EncoderLayer(\n",
        "        vocab_size=len(RU_TEXT.vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    decoder=DecoderLayer(\n",
        "        vocab_size=len(EN_TEXT.vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    src_pad_index=RU_TEXT.vocab.stoi[RU_TEXT.pad_token],\n",
        "    dest_pad_index=EN_TEXT.vocab.stoi[EN_TEXT.pad_token]\n",
        ").to(DEVICE)\n",
        "optimizer = optim.Adam(params=transformer.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=EN_TEXT.vocab.stoi[EN_TEXT.pad_token])\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in transformer.parameters() if p.requires_grad):,}')\n",
        "print(transformer)\n",
        "trainer = Trainer(model=transformer, optimizer=optimizer, scheduler=scheduler, criterion=criterion)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 113,979,609\n",
            "Transformer(\n",
            "  (encoder): EncoderLayer(\n",
            "    (dropout): Dropout(p=0.05, inplace=False)\n",
            "    (token_embedding): Embedding(174852, 256)\n",
            "    (position_encoding): PositionalEncodingLayer()\n",
            "    (encoder_block_layers): ModuleList(\n",
            "      (0): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): DecoderLayer(\n",
            "    (dropout): Dropout(p=0.05, inplace=False)\n",
            "    (token_embedding): Embedding(122585, 256)\n",
            "    (position_encoding): PositionalEncodingLayer()\n",
            "    (decoder_block_layers): ModuleList(\n",
            "      (0): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.05, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_ou): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (fc): Linear(in_features=256, out_features=122585, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ajmAIurrWX"
      },
      "source": [
        "!mkdir -p ./models\n",
        "!cp /content/drive/MyDrive/machine-translation-data/transformer.pth ./models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLKqBi0Vg1Zu"
      },
      "source": [
        "trainer.model.load_state_dict(torch.load('./models/transformer.pth'))\n",
        "trainer.model.to(DEVICE);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvr8umKBNXuL",
        "outputId": "57e96a0c-11f4-40b0-a9ef-d914331775bc"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 113,979,609 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbbnHE4jZjc"
      },
      "source": [
        "!mkdir -p models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiCK-OTndTGt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "a42ae1c7-a27f-4c43-b0a4-3b941ef76b56"
      },
      "source": [
        "train_iterator, valid_iterator, _ =  BucketIterator.splits((train_data, valid_data, valid_data), batch_size=BATCH_SIZE, device=DEVICE, sort=False)\n",
        "history = trainer.train(train_loader=train_iterator, valid_loader=valid_iterator, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 -     loss: 3.481 -     ppl: 32.484 -     acc: 5.127%: 100%|██████████| 30625/30625 [1:44:56<00:00,  4.86it/s]\n",
            "Epoch: 01 - val_loss: 3.198 - val_ppl: 24.472 - val_acc: 5.421%: 100%|██████████| 625/625 [00:50<00:00, 12.39it/s]\n",
            "Epoch: 02 -     loss: 3.187 -     ppl: 24.216 -     acc: 5.375%:  23%|██▎       | 7052/30625 [23:56<1:20:02,  4.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1f63bf80bce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mBucketIterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGRAD_CLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b7595ba84e07>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, valid_loader, n_epochs, grad_clip)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ppl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-b7595ba84e07>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, loader, epoch, grad_clip)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch_size, dest_len, vocab_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.01 GiB (GPU 0; 15.90 GiB total capacity; 12.16 GiB already allocated; 1.03 GiB free; 14.10 GiB reserved in total by PyTorch)\nException raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7ff57f7041e2 in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x1e64b (0x7ff57f95a64b in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10_cuda.so)\nframe #2: <unknown function> + 0x1f464 (0x7ff57f95b464 in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10_cuda.so)\nframe #3: <unknown function> + 0x1faa1 (0x7ff57f95baa1 in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10_cuda.so)\nframe #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7ff58266690e in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cuda.so)\nframe #5: <unknown function> + 0xf33949 (0x7ff580aa0949 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0xf4d777 (0x7ff580aba777 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cuda.so)\nframe #7: <unknown function> + 0x10e9c7d (0x7ff5bb856c7d in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0x10e9f97 (0x7ff5bb856f97 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7ff5bb961a1a in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #10: at::native::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x49e (0x7ff5bb5dfc3e in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x12880c1 (0x7ff5bb9f50c1 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x12c3863 (0x7ff5bba30863 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #13: at::empty_like(at::Tensor const&, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x101 (0x7ff5bb944b31 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #14: at::Tensor at::native::(anonymous namespace)::host_softmax_backward<at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue, true>(at::Tensor const&, at::Tensor const&, long, bool) + 0xa7 (0x7ff581ef0a97 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cuda.so)\nframe #15: at::native::log_softmax_backward_cuda(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x65a (0x7ff581edafaa in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cuda.so)\nframe #16: <unknown function> + 0xf215c0 (0x7ff580a8e5c0 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cuda.so)\nframe #17: <unknown function> + 0x11141d6 (0x7ff5bb8811d6 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #18: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7ff5bb90f649 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #19: <unknown function> + 0x2ec639f (0x7ff5bd63339f in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #20: <unknown function> + 0x11141d6 (0x7ff5bb8811d6 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #21: at::_log_softmax_backward_data(at::Tensor const&, at::Tensor const&, long, at::Tensor const&) + 0x119 (0x7ff5bb90f649 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #22: torch::autograd::generated::LogSoftmaxBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x1d7 (0x7ff5bd4af057 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #23: <unknown function> + 0x3375bb7 (0x7ff5bdae2bb7 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #24: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7ff5bdade400 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #25: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7ff5bdadefa1 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #26: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7ff5bdad7119 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\nframe #27: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7ff5cb277dea in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\nframe #28: <unknown function> + 0xbd6df (0x7ff63e33d6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #29: <unknown function> + 0x76db (0x7ff63f8106db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #30: clone + 0x3f (0x7ff63e94571f in /lib/x86_64-linux-gnu/libc.so.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVsCRcNufbEE"
      },
      "source": [
        "torch.save(trainer.model.state_dict(), './models/transformer.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZgzNOQoXIWY"
      },
      "source": [
        "!cp ./models/transformer.pth /content/drive/MyDrive/machine-translation-data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ybctUVAYK8",
        "outputId": "9a2d7c34-ccf3-4f0a-b23b-952955b5cba8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 10 08:19:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    32W / 250W |  14447MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFcY3q9dmIhr"
      },
      "source": [
        "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history['loss'], label='train')\n",
        "axes[0].plot(history['val_loss'], label='valid')\n",
        "axes[0].set_title('Loss history')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].grid(True)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['ppl'], label='train')\n",
        "axes[1].plot(history['val_ppl'], label='valid')\n",
        "axes[1].set_title('Perplexity history')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Perplexity')\n",
        "axes[1].grid(True)\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history['acc'], label='train')\n",
        "axes[2].plot(history['val_acc'], label='valid')\n",
        "axes[2].set_title('Top-5 Accuracy & BLEU history')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Accuracy & BLEU (%)')\n",
        "axes[2].grid(True)\n",
        "axes[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_pcK8xOmIhr"
      },
      "source": [
        "transformer.load_state_dict(torch.load('./models/transformer.pth'))\n",
        "transformer.to(DEVICE);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8LxG1gYiwJX"
      },
      "source": [
        "def find_path(tree):\n",
        "    path = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(path) == 0:\n",
        "            path.append(nodes[0])\n",
        "        else:\n",
        "            parent_id = path[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.id == parent_id:\n",
        "                    path.append(node)\n",
        "    return path\n",
        "\n",
        "def find_best_path(tree):\n",
        "    best = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(best) == 0:\n",
        "            best.append(nodes[0])\n",
        "        else:\n",
        "            nodes_eos = []\n",
        "            parent_id = best[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.eos:\n",
        "                    nodes_eos.append(node)\n",
        "                if node.id == parent_id:\n",
        "                    best.append(node)\n",
        "            if len(nodes_eos) > 0:\n",
        "                candidates = sorted([best[-1], *nodes_eos],\n",
        "                                    key=lambda node: node.logps,\n",
        "                                    reverse=True)\n",
        "                candidate = candidates[0]\n",
        "                if candidate.eos:\n",
        "                    best = [candidate]\n",
        "    return best\n",
        "\n",
        "class Node:\n",
        "    id_ = 0\n",
        "    \n",
        "    def __init__(self, token, states, logp=0., parent=None, eos=False):\n",
        "        self.__id = self.__class__.id_\n",
        "        self.__token = token\n",
        "        self.__states = states\n",
        "        self.__logp = logp\n",
        "        self.__parent_id = None if parent is None else parent.id\n",
        "        self.__eos = eos\n",
        "        self.__level = 0 if parent is None else parent.level + 1\n",
        "        self.__logps = logp if parent is None else parent.logps + logp\n",
        "        self.__class__.id_ += 1\n",
        "        \n",
        "    def __str__(self):\n",
        "        return f'Node[id={self.__id}, ' + \\\n",
        "                    f'index={EN.vocab.itos[self.__token.cpu().item()]}, ' + \\\n",
        "                    f'logp={self.__logp}, ' + \\\n",
        "                    f'logps={self.__logps}, ' + \\\n",
        "                    f'parent_id={self.__parent_id}, ' + \\\n",
        "                    f'level={self.__level}]'\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def parent_id(self):\n",
        "        return self.__parent_id\n",
        "    \n",
        "    @parent_id.setter\n",
        "    def parent_id(self, parent_id):\n",
        "        self.__parent_id = parent_id\n",
        "        \n",
        "    @property\n",
        "    def id(self):\n",
        "        return self.__id\n",
        "    \n",
        "    @id.setter\n",
        "    def id(self, id_):\n",
        "        self.__id = id_\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def states(self):\n",
        "        return self.__states\n",
        "    \n",
        "    @states.setter\n",
        "    def states(self, states):\n",
        "        self.__states = states\n",
        "      \n",
        "    @property\n",
        "    def eos(self):\n",
        "        return self.__eos\n",
        "    \n",
        "    @eos.setter\n",
        "    def eos(self, eos):\n",
        "        self.__eos = eos\n",
        "    \n",
        "    @property\n",
        "    def logps(self):\n",
        "        return self.__logps\n",
        "    \n",
        "    @logps.setter\n",
        "    def logps(self, logps):\n",
        "        self.__logps = logps\n",
        "        \n",
        "    @property\n",
        "    def level(self):\n",
        "        return self.__level\n",
        "    \n",
        "    @level.setter\n",
        "    def level(self, level):\n",
        "        self.__level = level\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScoI5AN1mIhr"
      },
      "source": [
        "def evaluate(model, data, beam_size, src_field, dest_field, max_len, device):\n",
        "    src_sentences = [*map(lambda example: example.src, data.examples)]\n",
        "    dest_sentences = [*map(lambda example: example.trg, data.examples)]\n",
        "    data = [*zip([*map(lambda word_list: src_field.process([word_list]), src_sentences)],\n",
        "                 [*map(lambda word_list: dest_field.process([word_list]), dest_sentences)])]\n",
        "    references, hypotheses, sources = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (src_sequence, dest_sequence) in tqdm.tqdm(enumerate(data), total=len(data), position=0, leave=True):\n",
        "            src_sequence, dest_sequence = src_sequence.to(device), dest_sequence.to(device)\n",
        "            src_mask = model.make_src_mask(src_sequence)\n",
        "            src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "            # Decoding\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=None)]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    # Get tokens that're already translated\n",
        "                    already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(tree))][::-1]).unsqueeze(0).to(device)\n",
        "                    dest_mask = model.make_dest_mask(already_translated)\n",
        "                    logit, _ = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                              dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                    \n",
        "                    logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps                    \n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=None,\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True) # Sort next_nodes to get the best\n",
        "                tree.append(next_nodes[:beam_size]) # Update the tree\n",
        "            best_path = find_best_path(tree) # Find the best path of the tree\n",
        "\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [dest_field.init_token, dest_field.eos_token], pred_translated[::-1])]\n",
        "\n",
        "            hypotheses.append(pred_translated) # Update hypotheses\n",
        "\n",
        "            # Update references\n",
        "            references.append([[dest_field.vocab.itos[indice] for indice in dest_sequence[0] if indice not in (\n",
        "                dest_field.vocab.stoi[dest_field.init_token],\n",
        "                dest_field.vocab.stoi[dest_field.eos_token],\n",
        "                dest_field.vocab.stoi[dest_field.pad_token]\n",
        "            )]])\n",
        "\n",
        "            # Update sources\n",
        "            sources.append([src_field.vocab.itos[indice]  for indice in src_sequence[0] if indice not in (\n",
        "                src_field.vocab.stoi[src_field.init_token],\n",
        "                src_field.vocab.stoi[src_field.eos_token],\n",
        "                src_field.vocab.stoi[src_field.pad_token]\n",
        "            )])\n",
        "    \n",
        "        assert len(hypotheses) == len(references) == len(sources)\n",
        "        bleu = bleu_score(hypotheses, references) # Calculate BLEU score\n",
        "    return hypotheses, references, sources, bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z4YL6aemIhr"
      },
      "source": [
        "bleu_scores = []\n",
        "for beam_size in [1]:\n",
        "    for name, data in [('validation', valid_data)]:\n",
        "        _, _, _, bleu = evaluate(model=transformer, data=data, beam_size=beam_size, src_field=RU_TEXT, dest_field=EN_TEXT, max_len=MAX_LEN, device=DEVICE)\n",
        "        bleu_scores.append((beam_size, name, bleu))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhmKUQwL31PF"
      },
      "source": [
        "for score in bleu_scores:\n",
        "    print(f'BLEU: {score[2]*100:.3f}% with beam_size={score[0]} on {score[1]} data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRfG8X1pHEBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9324af81-4293-41ac-c1f4-b5e0e9a965ee"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 55,872,985 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH6X3gMImIhs"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TzuCX4wmIhs"
      },
      "source": [
        "def translate(sentences, model, beam_size, src_field, dest_field, max_len, device):\n",
        "    if isinstance(sentences, list):\n",
        "        sentences = [*map(src_field.preprocess, sentences)]\n",
        "        targets = None\n",
        "    if isinstance(sentences, Dataset):\n",
        "        targets = [*map(lambda example: ' '.join(example.trg), sentences.examples)]\n",
        "        sentences = [*map(lambda example: example.src, sentences.examples)]\n",
        "    data = [*map(lambda word_list: src_field.process([word_list]), sentences)]\n",
        "    translated_sentences, attention_weights, pred_logps = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, src_sequence in tqdm.tqdm(enumerate(data), total=len(data), position=0, leave=True):\n",
        "            src_sequence = src_sequence.to(device)\n",
        "            src_mask = model.make_src_mask(src_sequence)\n",
        "            src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=())]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    # Get tokens that're already translated\n",
        "                    already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(tree))][::-1]).unsqueeze(0).to(device)\n",
        "                    dest_mask = model.make_dest_mask(already_translated)\n",
        "                    logit, attn_weights = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                              dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                      \n",
        "                    logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps                    \n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=(attn_weights,),\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True)\n",
        "                tree.append(next_nodes[:beam_size])\n",
        "            best_path = find_best_path(tree)[::-1]\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [\n",
        "                dest_field.init_token, dest_field.eos_token\n",
        "            ], pred_translated)]\n",
        "            translated_sentences.append(' '.join(pred_translated))\n",
        "            # Get probabilities\n",
        "            pred_logps.append(sum([*map(lambda node: node.logps, best_path)]))\n",
        "            # Get attention weights\n",
        "            attention_weights.append(best_path[-1].states[0].cpu().numpy())\n",
        "        sentences = [*map(lambda sentence: ' '.join(sentence), sentences)]\n",
        "    return sentences, translated_sentences, targets, attention_weights, pred_logps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bzUKUGJGyFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c8b54c-8413-4188-f892-92baa4d5c5db"
      },
      "source": [
        "test_sentences = list(map(lambda x: x.strip(), open('./test.ru', 'r').readlines()))\n",
        "test_sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['26. Вопрос о лесах необходимо вывести на более высокий уровень в рамках целей устойчивого развития, в том числе посредством включения в такие цели убедительных и четких целевых и рабочих показателей по лесам.',\n",
              " 'В рамках экологической экспертизы определены пять вариантов строительства и эксплуатации замещающей электростанции, которая восстановит мощность энергораспределительной сети Управления по состоянию до стихийного бедствия.',\n",
              " 'В ходе рассмотрения данного пункта повестки дня Рабочая группа будет кратко проинформирована Секретариатом о работе УНП ООН по содействию ратификации и осуществлению Протокола об огнестрельном оружии в рамках Глобальной программы по огнестрельному оружию.',\n",
              " 'В последние месяцы сирийское правительство позволило террористам использовать территорию своей страны в качестве базы, действуя с которой они устанавливают взрывные устройства на обочинах дорог, наносят ракетные удары по Израилю и обстреливают подразделения Армии обороны Израиля, дислоцированные на территории страны.',\n",
              " 'По мнению автора, Иммиграционная служба допускает, что эти события действительно имели место, несмотря на то что государство-участник считает их не относящимися к делу и не являющимися основанием для предоставления убежища.',\n",
              " '1. постановляет санкционировать увеличение численности личного состава МИНУСКА на 750 военнослужащих, 280 полицейских и 20 сотрудников исправительных учреждений в дополнение к персоналу, утвержденному в пункте 20 резолюции 2149 (2014);',\n",
              " 'В период с июня 2007 года по март 2008 года было проведено четыре раунда прямых переговоров между сторонами, но прогресса добиться не удалось, поскольку Марокко настаивало на том, чтобы ее предложение об автономии было единственной основой для переговоров.',\n",
              " 'БАПОР оказало помощь более чем 14 000 палестинских беженцев в рамках проводимой в общинах информационно-разъяснительной и профилактической работы, связанной с проблематикой насилия на гендерной почве, прав детей и прав человека, насилия в семье, беспризорности и сексуальных злоупотреблений.',\n",
              " '5. Комитет имел в своем распоряжении меморандум секретариата Конференции от 16 марта 2015 года о полномочиях представителей государств и Европейского союза, участвующих в Конференции.',\n",
              " 'В соответствии со статьей 28 Регламента в ее состав входят по должности Председатель и заместитель Председателя Трибунала, причем Председатель Трибунала является ее председателем.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FPeU0s4mIhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f940b41-e504-4882-e82e-a314cfe6663d"
      },
      "source": [
        "sentences, translated_sentences, dest_sentences, attention_weights, pred_logps = translate(sentences=test_sentences, model=transformer, beam_size=1, src_field=RU_TEXT,\n",
        "                                                                                           dest_field=EN_TEXT, max_len=MAX_LEN, device=DEVICE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:28<00:00,  3.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsYaV_X8PBoQ"
      },
      "source": [
        "with open(\"answer.txt\", 'w') as file:\n",
        "    for sent in translated_sentences:\n",
        "        file.write(sent + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_keF2reemIhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bd8807-0f2b-4512-eb49-96ec7fd870a6"
      },
      "source": [
        "# indexes = np.random.choice(1000, size=10, replace=False)\n",
        "indexes = range(len(sentences))\n",
        "for i in indexes:\n",
        "    text = f'Source: {sentences[i]}\\n'\n",
        "    # text += f'Ground truth translation: {dest_sentences[i]}\\n'\n",
        "    text += f'Predicted translation: {translated_sentences[i]}\\n'\n",
        "    print(text)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source: 26 . вопрос о лесах необходимо вывести на более высокий уровень в рамках целей устойчивого развития , в том числе посредством включения в такие цели убедительных и четких целевых и рабочих показателей по лесам .\n",
            "Predicted translation: 26 . the forests should be focused on a higher level of sustainable development , including through the inclusion of the objectives and the basic goals and the indicators of the population\n",
            "\n",
            "\n",
            "Source: в рамках экологической экспертизы определены пять вариантов строительства и эксплуатации замещающей электростанции , которая восстановит мощность энергораспределительной сети управления по состоянию до стихийного бедствия .\n",
            "Predicted translation: the environmental expertise are determined by five construction options and the <unk> power of the <unk> power network as to the current disaster .\n",
            "\n",
            "\n",
            "Source: в ходе рассмотрения данного пункта повестки дня рабочая группа будет кратко проинформирована секретариатом о работе унп оон по содействию ратификации и осуществлению протокола об огнестрельном оружии в рамках глобальной программы по огнестрельному оружию .\n",
            "Predicted translation: the secretariat will briefly report the secretariat to the secretariat on the work of the un secretariat on the implementation of the ratification and implementation of the protocol on the elimination of\n",
            "\n",
            "\n",
            "Source: в последние месяцы сирийское правительство позволило террористам использовать территорию своей страны в качестве базы , действуя с которой они устанавливают взрывные устройства на обочинах дорог , наносят ракетные удары по израилю и обстреливают подразделения армии обороны израиля , дислоцированные на территории страны .\n",
            "Predicted translation: in recent months , the government of israel has allowed terrorists to use the territory of their country as a base that they would like to deploy the devices on the roads\n",
            "\n",
            "\n",
            "Source: по мнению автора , иммиграционная служба допускает , что эти события действительно имели место , несмотря на то что государство - участник считает их не относящимися к делу и не являющимися основанием для предоставления убежища .\n",
            "Predicted translation: according to the author , the immigration service is concerned that these events have a place , despite the fact that the state party considers them not to be concerned with the\n",
            "\n",
            "\n",
            "Source: 1 . постановляет санкционировать увеличение численности личного состава минуска на 750 военнослужащих , 280 полицейских и 20 сотрудников исправительных учреждений в дополнение к персоналу , утвержденному в пункте 20 резолюции 2149 ( 2014 );\n",
            "Predicted translation: 1 . decides to raise the personal number of persons with disabilities , 280 police and 20 officers of correctional institutions in addition to staff , accused of 20 resolution of <unk>\n",
            "\n",
            "\n",
            "Source: в период с июня 2007 года по март 2008 года было проведено четыре раунда прямых переговоров между сторонами , но прогресса добиться не удалось , поскольку марокко настаивало на том , чтобы ее предложение об автономии было единственной основой для переговоров .\n",
            "Predicted translation: four round - round talks between the parties , but progress was not achieved since morocco had to make a proposal to the extent that the autonomy had been the only basis\n",
            "\n",
            "\n",
            "Source: бапор оказало помощь более чем 14 000 палестинских беженцев в рамках проводимой в общинах информационно - разъяснительной и профилактической работы , связанной с проблематикой насилия на гендерной почве , прав детей и прав человека , насилия в семье , беспризорности и сексуальных злоупотреблений .\n",
            "Predicted translation: the kyrgyz republic has helped to assist in more than 14 , 000 palestinian refugees in the area of information and sexual studies , and sexual abuse , related to sexual abuse\n",
            "\n",
            "\n",
            "Source: 5 . комитет имел в своем распоряжении меморандум секретариата конференции от 16 марта 2015 года о полномочиях представителей государств и европейского союза , участвующих в конференции .\n",
            "Predicted translation: 5 . the committee has had a memorandum of conference at the end of march 2015 on the participation of representatives of the states and the european union participating in the conference\n",
            "\n",
            "\n",
            "Source: в соответствии со статьей 28 регламента в ее состав входят по должности председатель и заместитель председателя трибунала , причем председатель трибунала является ее председателем .\n",
            "Predicted translation: in accordance with article 28 of the terms of the article , the chairman of the office is the chairman of the tribunal .\n",
            "\n",
            "\n",
            "Source: секретариат связался с секретариатом конвенции о биологическом разнообразии по поводу данных , собранных в процессе выявления экологически или биологически значимых морских районов .\n",
            "Predicted translation: the secretariat contacted the secretariat of the convention on biological diversity on data collected in the process of identifying environmentally or significant marine areas .\n",
            "\n",
            "\n",
            "Source: 8 . на своем 1м заседании подготовительный комитет постановил рекомендовать конференции продолжить переговоры по проекту рамочной программы по уменьшению опасности бедствий на период после 2015 года в главном комитете .\n",
            "Predicted translation: 8 . at its plenary session , the steering committee invited the conference to continue negotiating on the project of the programme for the reduction in the risk of disaster disaster during\n",
            "\n",
            "\n",
            "Source: истинная цель широкомасштабной враждебной политики сша в отношении кндр состоит в том , чтобы окружить континент плотным кольцом блокады и чтобы дальний восток и азиатский континент попустительствовали американской тактике самоуправства и произвола .\n",
            "Predicted translation: the true objective of the u . s . - based strategic deterrence is to ensure that the united states ' s colonial continent is a strong and viable middle east and\n",
            "\n",
            "\n",
            "Source: вновь подтверждая , что применение химического оружия является серьезным нарушением международного права , и вновь заявляя , что виновные в любом применении химического оружия должны нести за это ответственность ,\n",
            "Predicted translation: again , chemical weapons are a serious violation of international law , and again the perpetrators that the nuclear weapons should be responsible for this responsibility , and that the perpetrators of\n",
            "\n",
            "\n",
            "Source: не допускать осквернения памяти миллионов жертв , погибших в годы второй мировой войны по вине нацистских преступников и их пособников , решительно осуждать соответствующие планы и тем более действия ;\n",
            "Predicted translation: not to make the memory of millions of victims killed in the second world war on nazi criminals and their accomplices , and to strictly destroy the relevant plans and to act\n",
            "\n",
            "\n",
            "Source: кроме того , мы сможем , с опорой на итоги проведенного 19 февраля вашингтонского саммита , рассмотреть вопрос о мерах , необходимых для борьбы с терроризмом и насильственным экстремизмом при соблюдении прав человека и норм международного гуманитарного права .\n",
            "Predicted translation: in addition , we can , with the results of the results of the meeting on february 19 , the chinese summit , consider the question of measures necessary to combat terrorism\n",
            "\n",
            "\n",
            "Source: в период с 22 декабря 2014 года по 22 февраля 2015 года вооруженные террористические группы подвергали сирийские города бомбардировкам и обстрелам из артиллерийских орудий , в результате чего 325 сирийских гражданских лиц , в том числе 57 детей , были убиты и 766 гражданских лиц , в том числе 141 ребенок , получили ранения .\n",
            "Predicted translation: in the period from december 22 to december 22 , 2015 , the armed groups of the armed group of the chechen people were killed by the city of the cossacks and\n",
            "\n",
            "\n",
            "Source: одрч , с одной стороны , является независимым подразделением , а с другой -- зависит в то же время от подразделений программы проон в плане распространения идей и использования базы знаний страновых отделений .\n",
            "Predicted translation: the <unk> , on the one hand , is an independent worker , and on the other , depends on the undp programme departments in the field of distribution of ideas and\n",
            "\n",
            "\n",
            "Source: они призвали к разработке системы открытой , инклюзивной , неделимой и транспарентной безопасности и сотрудничества в регионе на основе общепризнанных принципов международного права .\n",
            "Predicted translation: they called for the development of open , open , fair , and transparent security and cooperation in the region , as well as the international law .\n",
            "\n",
            "\n",
            "Source: план работы по разведке кобальтоносных железомарганцевых корок на поднятии риу - гранди , проводимой компанией << компанья де пескиза де рекурсош минерайш са >>, поручителем которой выступает бразилия , был утвержден советом в июле 2014 года .\n",
            "Predicted translation: the <unk> <unk> <unk> <unk> <unk> <unk> <unk> , a pilot - <unk> , a company of <unk> de <unk> de <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "\n",
            "\n",
            "Source: совет будет осуществлять надзор за разработкой общей инфраструктуры управления информацией , включая единый глобальный цифровой архив официальной документации , исследований и статистики .\n",
            "Predicted translation: the council will monitor the general infrastructure of information management , including the global digital archive of official documentation , research , and statistics .\n",
            "\n",
            "\n",
            "Source: в министерстве была создана рабочая группа с целью сбора информации о положении женщин в сельских районах и в настоящее время ведется работа над планом действий по развитию и укреплению роли и положения женщин в сельских районах .\n",
            "Predicted translation: the ministry has established a working group to gather information on the position of women in rural areas and now work on the development and strengthening of the role and position of\n",
            "\n",
            "\n",
            "Source: кроме того , экстремистски настроенные израильские поселенцы продолжают терроризировать палестинский народ , ежедневно совершая акты , связанные с насилием , разрушениями и запугиванием и часто приводящие к жертвам среди гражданского населения , включая детей .\n",
            "Predicted translation: in addition , israeli invaders continue to withstand palestinian people , and to act on violence , and to bring and adapt to victims among civilian populations , including children .\n",
            "\n",
            "\n",
            "Source: 39 . комитет обеспокоен тем , что все более частое использование в государстве - участнике гендерно нейтральных формулировок и стратегий может непреднамеренно приводить к усугублению фактического неравенства между женщинами и мужчинами .\n",
            "Predicted translation: 39 . the committee is concerned that more often the use of the state is the embodiment of the conscious and the strategies may lead to the rapid deterioration between women and\n",
            "\n",
            "\n",
            "Source: просьба представить информацию о мерах , принятых государством - участником для эффективного предотвращения насилия в семье и гендерно мотивированных убийств , в том числе убийств женщин и так называемых преступлений в защиту чести .\n",
            "Predicted translation: please provide information on measures taken by the state party to effectively prevent violence in the family and to the extent of increased violence , including murder of women and so -\n",
            "\n",
            "\n",
            "Source: власть обязана , прежде всего , гарантировать права женщинам и нести полную ответственность за предоставление возможностей социальной и творческой реализации для максимально возможного количества представительниц женского населения планеты .\n",
            "Predicted translation: the power is obliged to guarantee the right of women and to provide full responsibility for the provision of social and creative implementation for the maximum possible number of women of the\n",
            "\n",
            "\n",
            "Source: предположительно , дальнейшие бомбардировки произошли 23 марта и 6 апреля в делиебе , округ рага , и 8 и 9 апреля в ньинбули и ачане , в округе западный авейль , и в майом - ангоке , в округе северный авейль .\n",
            "Predicted translation: the previous bombing of the bombing was held on march 23 and april 6 in <unk> , <unk> district , and 8th april in <unk> and <unk> , in the <unk> district\n",
            "\n",
            "\n",
            "Source: 2 . заявляет , что эритрея больше других государств озабочена восстановлением безопасности и стабильности в йемене ввиду исторически сложившихся добрососедских отношений между двумя странами и народами ;\n",
            "Predicted translation: 2 . the fact that the rest of the states are more concerned with the security and stability of yemen is in the context of the ancient contradiction between the two states\n",
            "\n",
            "\n",
            "Source: в качестве лидера группы альхуси неоднократно угрожал йеменским властям организацией новых беспорядков , если они не выполнят его требования , и заключил под стражу президента хади , премьер - министра и основных членов кабинета .\n",
            "Predicted translation: as the leader of the <unk> group , the government of new riots , if they are not under the requirements , and the government of the <unk> , the prime minister\n",
            "\n",
            "\n",
            "Source: специальный посланник , основываясь на результатах оценки , представленных ему обеими миссиями , определит , имеются ли условия для осуществления этой инициативы по введению моратория на первоначальный период продолжительностью шесть недель .\n",
            "Predicted translation: the special envoy based on the evaluation presented by both departments is aware of whether the conditions for implementing this initiative are to be implemented by the original period of six weeks\n",
            "\n",
            "\n",
            "Source: подчеркивая , что масштабы последствий взрыва ядерного оружия и связанные с этим угрозы порождают глубокие моральные и этические вопросы , которые выходят за рамки дебатов относительно законности ядерного оружия ,\n",
            "Predicted translation: it is worth noting that the extent of nuclear nuclear deterrence and the threat of the threat of deep moral and ethical issues that are beyond the framework of nuclear weapons ,\n",
            "\n",
            "\n",
            "Source: имею честь сослаться на резолюцию 2206 ( 2015 ) совета безопасности , принятую 3 марта 2015 года , в которой совет постановил создать группу экспертов по южному судану на первоначальный период в 13 месяцев .\n",
            "Predicted translation: the honour of the resolution of the security council is to be addressed by the council of ministers , on 3 march 2015 , which the council has appointed to establish a\n",
            "\n",
            "\n",
            "Source: в ходе закрытых консультаций , состоявшихся по завершении заседания , члены совета осудили жестокое убийство 21 египетского гражданина в ливии и выразили соболезнования правительству и народу египта .\n",
            "Predicted translation: during the meeting , members of the council of the brutal murder of the 21 - year - old people of the republic of croatia and expressed condolences to the government and\n",
            "\n",
            "\n",
            "Source: имею честь препроводить настоящим заявление министерства иностранных дел грузии от 18 марта 2015 года , касающееся тридцать первого раунда женевских международных дискуссий ( см . приложение ).\n",
            "Predicted translation: the honour of the ministry of foreign affairs of georgia is to be honored on 18 march 2015 , and to celebrate thirty - first round of international trilateral discussions ( see\n",
            "\n",
            "\n",
            "Source: 7 . вопрос о пересмотре методов работы постоянного форума рассматривался по пункту 8 повестки дня << будущая работа постоянного форума , включая вопросы экономического и социального совета и новые вопросы >>.\n",
            "Predicted translation: 7 . the question of reviewing the work of the permanent forum was discussed on the agenda of the eighth day of the comprehensive work of the ongoing forum , including the\n",
            "\n",
            "\n",
            "Source: 32 . комитет рекомендует государству - участнику принять меры для снижения высокого уровня распространенности абортов в гренландии , в том числе за счет внедрения программ просвещения в области полового и репродуктивного здоровья , в первую очередь в школах .\n",
            "Predicted translation: 32 . the committee recommends that the state party take measures to reduce the high levels of abortion in greenland , including through the implementation of the programmes of sexual education and\n",
            "\n",
            "\n",
            "Source: она полностью вовлечена в усилия , предпринимаемые европейским союзом в целях поддержки одвзяи , конкретным проявлением которой стало принятое советом европейского союза решение о поддержке союзом деятельности подготовительной комиссии одвзяи .\n",
            "Predicted translation: it is fully integrated into efforts undertaken by the european union to support the <unk> , a particular manifestation of which the council of the european union has become a coordinating decision\n",
            "\n",
            "\n",
            "Source: таким образом , инвестиции в сферу водоснабжения и санитарии настоятельно необходимы для того , чтобы построить более справедливое и равноправное общество , в котором женщины и мужчины , девочки и мальчики смогут на законных основаниях рассчитывать на более комфортные условия жизни и на благополучие .\n",
            "Predicted translation: thus , investments in water and sanitation are necessary to build a more equitable and normal society in which women and men , girls and boys can rely on the legitimate conditions\n",
            "\n",
            "\n",
            "Source: по итогам обычных для таких случаев консультаций я хотел бы сообщить вам , что намерен назначить г - на яна кубиша ( словакия ) моим специальным представителем по ираку и главой миссии организации объединенных наций по оказанию содействия ираку .\n",
            "Predicted translation: as a result , i would like to inform you that i would like to appoint mr . <unk> , my special envoy to iraq and the united nations mission on iraq\n",
            "\n",
            "\n",
            "Source: в рамках программ планирования семьи необходимо предпринимать шаги для обеспечения оказания услуг всем лицам , отвечающим необходимым критериям , даже тем лицам , для кого обычные услуги здравоохранения не являются легко доступными .\n",
            "Predicted translation: the family planning programme needs to take steps to ensure that all persons who need criteria are necessary , even those who are not available to whom ordinary health care services are\n",
            "\n",
            "\n",
            "Source: совет безопасности выражает серьезную обеспокоенность в связи с сообщениями о нарушениях и попрании прав человека и массовом перемещении гражданского населения , в том числе в соседние с нигерией страны .\n",
            "Predicted translation: the security council expresses serious concern on the reports on human rights and the human rights and the mass movement of the civilian population , including neighbouring countries .\n",
            "\n",
            "\n",
            "Source: 1 . ирландия представляет настоящий краткий доклад во исполнение действия 20 плана действий , принятого конференцией 2010 года участников договора о нераспространении ядерного оружия по рассмотрению действия договора .\n",
            "Predicted translation: 1 . ireland represents a present brief report to the action plan , to take part in the conference of the 2010 conference of the parties of the npt treaty on nuclear\n",
            "\n",
            "\n",
            "Source: однако при рассмотрении просьбы ирака члены совета управляющих признали , что в настоящее время в стране наблюдается весьма серьезный кризис в плане безопасности , требующий значительных затрат , и заявили о своей солидарности с ираком .\n",
            "Predicted translation: however , the iraqi governing board members have acknowledged that the country is currently a very serious crisis in the security plan , which is critical to the extent of the security\n",
            "\n",
            "\n",
            "Source: комитету далее сообщили , что на этапе ликвидации миссии сроки мероприятий по списанию и ликвидации были сокращены , с тем чтобы завершить процесс ликвидации к установленному сроку .\n",
            "Predicted translation: the committee further noted that the implementation of the programme of the reporting period and the elimination of the measures was reduced to the end of the process to complete the elimination\n",
            "\n",
            "\n",
            "Source: отмечая необходимость в финансировании расходов , связанных с расследованиями или судебным преследованием , осуществляемыми международным уголовным судом , в том числе в связи с ситуациями , переданными суду советом безопасности ,\n",
            "Predicted translation: noting the need for the funding for the defence or prosecution , the international criminal court , including the security council , the security council , the security council , the security\n",
            "\n",
            "\n",
            "Source: по имеющимся оценкам , было разрушено или серьезно повреждено 100 000 домов и причинен серьезный материальный ущерб общественной инфраструктуре , в том числе единственной электростанции в газе и важнейшим инфраструктурным объектам водоснабжения и санитарии .\n",
            "Predicted translation: the estimated estimates have been destroyed or serious damage to the house and the major waste of the public infrastructure , including the only gas and water and sanitation facility .\n",
            "\n",
            "\n",
            "Source: он представляет собой первую часть доклада генерального секретаря о событиях и проблемах , относящихся к вопросам океана и морскому праву , который будет представлен ассамблее на рассмотрение на ее семидесятой сессии .\n",
            "Predicted translation: it represents the first part of the secretary - general ' s report on the events and issues related to ocean and sea law , which will be presented to the assembly\n",
            "\n",
            "\n",
            "Source: от обязательств к результатам : реформирование государственных учреждений в целях содействия всеохватной разработке и интеграции политики в деле осуществления и контроля за осуществлением целей в области устойчивого развития :\n",
            "Predicted translation: from the results of the results : the reform of state institutions to help develop and integrate policies in the implementation and control of the goals of sustainable development :\n",
            "\n",
            "\n",
            "Source: в сфере гарантий соединенные штаты провели национальные , региональные и международные учебные курсы по государственным системам учета и контроля ядерных материалов и дополнительному протоколу и оказали поддержку в проведении таких курсов .\n",
            "Predicted translation: the united states has held national , regional and international training courses on state - controlled systems for the state registration and monitoring of nuclear materials and the optional protocol and has\n",
            "\n",
            "\n",
            "Source: в этой связи хочу сообщить вам , что , проконсультировавшись с комитетом совета безопасности , учрежденным резолюцией 1572 ( 2004 ) по котд ' ивуару , я назначил следующих экспертов :\n",
            "Predicted translation: in this regard , i would like to tell you that , with the committee of security , the security council , the <unk> <unk> ( 2004 ) on <unk> ' <unk>\n",
            "\n",
            "\n",
            "Source: соответственно , объем предлагаемых ассигнований по данному разделу был определен на основе установленной методологии , но с учетом результатов стратегического обзора капитальных активов .\n",
            "Predicted translation: accordingly , the volume of proposed reference under section was determined on the basis of the methodology , but due to the results of the strategic review of the capital asset .\n",
            "\n",
            "\n",
            "Source: 1 . неотъемлемое право на использование ядерной энергии в мирных целях является одним из основных компонентов договора о нераспространении ядерного оружия наряду с ядерным разоружением и нераспространением .\n",
            "Predicted translation: 1 . the right to use nuclear energy is one of the main components of the nuclear weapons treaty , along with nuclear weapons and armaments .\n",
            "\n",
            "\n",
            "Source: настоящий документ представляет собой краткое изложение более масштабного исследования по трансграничным вопросам , включая признание права коренных народов на трансграничную торговлю товарами и услугами и ее осуществление через милитаризованные районы .\n",
            "Predicted translation: this document represents a brief interpretation of a broader study on the common issues , including recognition of the rights of indigenous peoples to the origin of goods and services and through\n",
            "\n",
            "\n",
            "Source: ассоциация подчеркивает , что соглашение относительно запрета и ликвидации ядерного оружия станет важным шагом на пути к изменению самого дискурса по вопросам безопасности в пользу установления политики обеспечения безопасности , в которой предпочтение отдавалось бы мирным решениям .\n",
            "Predicted translation: the association stresses that the agreement on the prohibition and elimination of nuclear weapons will be an important step towards the change of the chernobyl security policy in favor of building security\n",
            "\n",
            "\n",
            "Source: имею честь препроводить настоящим заявление министерства иностранных дел украины в связи с арестом заместителя председателя меджлиса крымско - татарского народа ахтема чийгоза ( см . приложение ).\n",
            "Predicted translation: the honour of the ministry of foreign affairs of ukraine is to be honored by the vice - president of the moldavian and tatar people of the <unk> <unk> ( see annex\n",
            "\n",
            "\n",
            "Source: мы продолжим работу с местными общинами и разработку политики и программ по борьбе с вышеуказанными проблемами , чтобы обеспечить всем женщинам надлежащее физическое и психическое здоровье для полной , продуктивной жизни .\n",
            "Predicted translation: we will continue working with local communities and policies and programmes to combat the problem to ensure that all women are well - known and healthy and healthy health for full ,\n",
            "\n",
            "\n",
            "Source: 7 . миссия продолжит поддерживать упрочение мира и всеохватный и транспарентный политический диалог с участием всех конголезских заинтересованных сторон с целью продолжения процесса примирения и демократизации .\n",
            "Predicted translation: 7 . mission will continue to support the peace and the world ' s commitment and the political dialogue with all the stakeholders concerned to continue the process of reconciliation and democratization\n",
            "\n",
            "\n",
            "Source: вышеуказанные данные не включают в себя гражданских лиц , которые погибли , которым перерезали горло или которые были убиты какими - либо другими жестокими , преступными способами , применяемыми террористическими организациями .\n",
            "Predicted translation: the above data is not included in civilians who have killed the throat or who have killed some other harmful , criminal , criminal , or terrorist attacks .\n",
            "\n",
            "\n",
            "Source: чтобы получить доступ к этому праву , реализовать или сохранить его женщинам приходится вести неустанную борьбу с такими явлениями , как лишение их возможности контролировать рождаемость , изнасилование , используемое в качестве орудия войны , клитеродектомия или криминализация гомосексуализма .\n",
            "Predicted translation: to access this law , implement or preserve it , women have to fight against such phenomena as their ability to control , protect , sexual , use , use , war\n",
            "\n",
            "\n",
            "Source: доминиканская республика создала фонд для женщин - пользователей лесов , с помощью которого им оказывается помощь в производстве продуктов питания , заготовке трав и сборе и продаже лесных побочных продуктов , включая топливную древесину .\n",
            "Predicted translation: the federal republic has created a foundation for women - users of forest , with which they can help in food production , food and food and food and food and food\n",
            "\n",
            "\n",
            "Source: поскольку комитет является единственным органом организации объединенных наций , занимающимся исключительно налоговыми вопросами , его работа и последующая деятельность в области финансирования развития тесно взаимосвязаны и дополняют друг друга .\n",
            "Predicted translation: the committee is the only body of the united nations , which is concerned exclusively with the tax issues , its work and operational activities in the field of development , and\n",
            "\n",
            "\n",
            "Source: в 2014 году объединенная программа совместно с фондом компании << мак >> по борьбе со спидом начали осуществлять глобальную кампанию с участием звезд мирового шоу - бизнеса с целью увеличить число молодых людей , знающих о своем серопозитивном статусе .\n",
            "Predicted translation: in 2014 , the joint programme of cooperation with the company has organized a team of transnational teams to combat aids began to implement the world ' s campaign with the participation\n",
            "\n",
            "\n",
            "Source: так , по информации организаций системы организации объединенных наций , в декабре 2014 года с сирийской территории продовольственная помощь была доставлена 3 , 6 миллиона человек , а медицинская помощь -- 500 000 человек .\n",
            "Predicted translation: for example , in december 2014 , the united nations system of information system was delivered to 3 . 6 million people , while medical assistance was 500 000 people .\n",
            "\n",
            "\n",
            "Source: один из выступавших отметил также , что в ходе специальной сессии можно особо отметить роль унп оон в области международного контроля над наркотиками , которое пользуется поддержкой других специализированных учреждений , фондов и программ организации объединенных наций .\n",
            "Predicted translation: one of the physicists noted that the special session could be noted by the un special rapporteur in the field of drug control , which is used by other specialized agencies ,\n",
            "\n",
            "\n",
            "Source: министры иностранных дел китая и россии вновь подтвердили значение , которое они придают статусу индии в международных делах , и поддержали ее стремление играть более весомую роль в организации объединенных наций .\n",
            "Predicted translation: the foreign ministers and russia have reaffirmed the importance they are in the status of india in international affairs , and supported its efforts to play more more important in the united\n",
            "\n",
            "\n",
            "Source: грузия и нигер полностью погасили свою задолженность в первой половине 2007 года , полностью выполнив таким образом свои планы до истечения сроков , указанных в пятом годовом докладе .\n",
            "Predicted translation: georgia and romania have fully funded their debt in the first half of 2007 , fully implementing their plans until the fifth periodic report .\n",
            "\n",
            "\n",
            "Source: 174 . участники единодушно согласились с тем , что торговля находящимися под угрозой исчезновения видами дикой фауны и флоры представляет собой серьезное препятствие на пути реализации универсальных прав человека и достижения мира , безопасности и развития .\n",
            "Predicted translation: 174 . the participants agree that trade is under threat to the endangered species of wild species and flora is a serious obstacle to the implementation of universal human rights and achievements\n",
            "\n",
            "\n",
            "Source: имею честь настоящим препроводить вам вербальную ноту , касающуюся церемонии подписания кодекса добросовестного поведения средств массовой информации и журналистов в ходе выборов , которые планируется провести в бурунди в 2015 году ( см . приложение ).\n",
            "Predicted translation: the honour of this campaign is to you to the present - day , which is intended to conduct burundi in 2015 ( see annex ).\n",
            "\n",
            "\n",
            "Source: основная цель этого мероприятия заключается в презентации и обсуждении глобального исследования , посвященного договору о нераспространении , и предоставлении молодым ученым возможности высказать свое мнение по поводу нынешних и будущих проблем и возможностей , связанных с этим договором .\n",
            "Predicted translation: the main objective of this action is to discuss and discuss the global research treaty , and to provide a young scientist with opportunities to express their views on current and future\n",
            "\n",
            "\n",
            "Source: в суровые годы войны на полях сражений и на трудовом фронте ярко проявились нерушимая дружба и высочайший патриотизм наших народов , завоевавших в едином строю общую победу .\n",
            "Predicted translation: in the extreme years of war in combat and the labour front , the sudden <unk> of friendship and the deep - up of our people , which are in the common\n",
            "\n",
            "\n",
            "Source: наше предложение расследовать нарушения режима прекращения огня для установления ответственных за конкретные инциденты остается в силе вместе с другими мерами по укреплению доверия и безопасности .\n",
            "Predicted translation: our proposal to investigate the ceasefire ' s failure to establish specific incidents is to be solved together with other measures to strengthen confidence and security .\n",
            "\n",
            "\n",
            "Source: в некоторых зонах защиты гражданских лиц , в том числе в бентиу и малакале , непрерывный приток внутренне перемещенных лиц увеличивает давление на объекты и приводит к снижению качества предоставляемых услуг .\n",
            "Predicted translation: in some areas , protection of civilians , including <unk> and <unk> , continued influx of internally displaced persons , increases in the pressure on objects and leads to the reduction of\n",
            "\n",
            "\n",
            "Source: на западном берегу , включая восточный иерусалим , в результате сноса домов израильскими властями рекордное число палестинцев ( около 1200 человек ) осталось без крова , и это при том , что строительство поселений и поселенческая активность не прекращались .\n",
            "Predicted translation: in the west bank , including east jerusalem , as a result of the demolition of the houses of the israeli authorities , the number of palestinians ( about 1200 people )\n",
            "\n",
            "\n",
            "Source: это позволит магатэ выполнять свою предполагаемую функцию эффективной проверки выполнения будущей конвенции по ядерному оружию или договора о запрещении производства расщепляющегося материала , охватывая все виды ядерной деятельности и все существующие запасы ядерных материалов .\n",
            "Predicted translation: this will allow the iaea to perform its operational function in its effective verification of the future convention on weapons or contract of the production of the fissile material , which will\n",
            "\n",
            "\n",
            "Source: комитет заключил , что экваториальная гвинея по - прежнему демонстрирует чрезмерную зависимость от углеводородного сектора , а высокий уровень дохода на душу населения не соответствует низкому показателю человеческого капитала .\n",
            "Predicted translation: the committee concluded that the inter - ethnic guinea was still demonstrating the dependence on the cuban sector , and the high level of the population ' s income is not consistent\n",
            "\n",
            "\n",
            "Source: буду признателен вам за распространение текста настоящего письма и приложения к нему в качестве документа генеральной ассамблеи по пунктам 35 и 36 повестки дня и в качестве документа совета безопасности .\n",
            "Predicted translation: i will thank you for the dissemination of this text and application to it as the general assembly on the subject of the 35 and 36 agenda and as the security council\n",
            "\n",
            "\n",
            "Source: сотрудник по расследованиям уровня с - 4 будет также оказывать следственным группам помощь в установлении фактической информации оперативного характера , особенно в связи с более сложными случаями , и будет подотчетен главному следователю в найроби .\n",
            "Predicted translation: the staff will also benefit from the team to assist in identifying the actual information of the operational nature , especially in relation to more advanced cases , and will be able\n",
            "\n",
            "\n",
            "Source: иначе чем целенаправленной расправой над гражданским населением города , жители которого никогда не желали и не желают иметь ничего общего с террористическими группировками , это назвать нельзя .\n",
            "Predicted translation: otherwise , the population of the city is not known to be a population of the people who never wanted to have anything to do with the terrorist population , that is\n",
            "\n",
            "\n",
            "Source: в этих целях украина восстановит управление сегментом своей банковской системы в районах , затронутых конфликтом , и , возможно , будет создан международный механизм для облегчения таких переводов .\n",
            "Predicted translation: in these purposes , ukraine will be able to manage its banking system in areas , districts , and may be established by the international mechanism to facilitate such translations .\n",
            "\n",
            "\n",
            "Source: в этой связи имею честь информировать вас о том , что по поручению моего правительства я обращаюсь с просьбой о сохранении следующих пунктов , перечисленных в пункте 3 вышеупомянутого документа :\n",
            "Predicted translation: in this regard , i am pleased to inform you that i am going to ask for the following points listed in paragraph 3 of the original document :\n",
            "\n",
            "\n",
            "Source: они направлены на расширение участия гражданского общества в процессе реформирования системы уголовного правосудия , включая надзор и контроль со стороны граждан за эффективностью работы систем уголовного правосудия , их объективностью и за соблюдением ими прав человека .\n",
            "Predicted translation: they are aimed at the expansion of civil society in the process of reforming criminal justice , including monitoring and monitoring of citizens for the effectiveness of the work of criminal justice\n",
            "\n",
            "\n",
            "Source: турецкий ракетный катер p - 336 вторгся в территориальные воды республики кипр и незаконно воспользовался закрытым портом амохостос , приняв участие в военно - морских учениях оккупационных сил .\n",
            "Predicted translation: turkish marines of the ural region of the ural region of the republic of cyprus and illegally took the <unk> port , taking part in the military - marine military cycle of\n",
            "\n",
            "\n",
            "Source: 4 . обеспечить постоянно действующий мониторинг на украинско - российской государственной границе и верификацию со стороны обсе с созданием зоны безопасности в приграничных районах украины и российской федерации .\n",
            "Predicted translation: 4 . ensure that the monitoring of the ukrainian - russian border is constantly monitoring and the osce ' s security zone in the caspian regions and the russian federation .\n",
            "\n",
            "\n",
            "Source: признавая , что содействие приобретению молодыми людьми навыков усилит их способность принимать осознанные решения в отношении жизни и работы и расширит их возможности в плане получения доступа на претерпевающие изменения рынки труда ,\n",
            "Predicted translation: recognizing that young people ' s assistance to raise their skills to make their ability to make a balanced decision on life and to increase their ability to access the market ,\n",
            "\n",
            "\n",
            "Source: 12 . в соответствии с законом о предупреждении насилия в семье разработана и принята национальная стратегия предупреждения насилия в семье ( 2014 -- 2016 годы ).\n",
            "Predicted translation: 12 . in accordance with the law on preventing violence in the family , the national strategy for preventing domestic violence in the family ( 2014 - 2016 ).\n",
            "\n",
            "\n",
            "Source: 3 . сообщаемые по каждой рубрике затраты следует , насколько это возможно , приводить в следующей разбивке : a ) эксплуатационные затраты ; b ) капитальные затраты ; с ) расходы на укомплектование штатов и содержание персонала ; d ) накладные расходы .\n",
            "Predicted translation: 3 . the cost of each category shall be as far as possible in the following paragraph shall be reimbursed : ( a ) operational costs ; ( b ) capital expenditures\n",
            "\n",
            "\n",
            "Source: юнсоа продолжает оказывать поддержку в деле предоставления административных , финансовых и технических услуг этой интегрированной миссии в рамках комплексной рамочной программы во всех штаб - квартирах и региональных отделениях .\n",
            "Predicted translation: <unk> continues to support the provision of administrative , financial and technical services of this integrated mission within the integrated framework of the integrated framework of the programme in all headquarters -\n",
            "\n",
            "\n",
            "Source: еще один семинар - практикум -- по << зеленой >> экономике и социальным аспектам неистощительного ведения лесного хозяйства -- был проведен в сантандере , испания , в апреле 2014 года ( во исполнение пункта 5 нынешней программы работы << леса европы >>).\n",
            "Predicted translation: another seminar - the workshop on the caspian - led green economy and social aspects of forestry - was held in <unk> , spain , in april 2014 ( 5 current programme\n",
            "\n",
            "\n",
            "Source: в 2005 году было создано управление служб здравоохранения территории -- автономное учреждение , которому подчиняются все государственные медицинские службы министерства здравоохранения и социального развития .\n",
            "Predicted translation: in 2005 , the health services management was established , which was established , in the country , which all public health care services and social development were established .\n",
            "\n",
            "\n",
            "Source: вновь призывая все стороны в йемене демонстрировать приверженность урегулированию своих разногласий с помощью диалога и консультаций , отвергнуть акты насилия как средство достижения политических целей и воздерживаться от провокаций ,\n",
            "Predicted translation: once again , the parties have demonstrated the commitment to resolve their conflicts through dialogue and consultations , and to remove violence as a means of achievement of political objectives and refraining\n",
            "\n",
            "\n",
            "Source: недавний демарш африканского союза , призвавшего к осуществлению взаимодействия между его << специальным посланником >> г - ном жоакимом чиссано и советом безопасности , является для королевства марокко совершенно неприемлемым .\n",
            "Predicted translation: the recent beslan fort of the african union , which is to take the interaction between its special envoy , the fifth century , the <unk> of the <unk> and the council\n",
            "\n",
            "\n",
            "Source: соответственно , хочу сообщить вам о том , что после консультаций с комитетом совета безопасности , учрежденным резолюцией 2206 ( 2015 ) по южному судану , я назначил следующих экспертов :\n",
            "Predicted translation: accordingly , i would like to inform you that after consultation with the security council committee , the security council , the <unk> ( 2015 ) on the eve of the fourteenth\n",
            "\n",
            "\n",
            "Source: в 2013 году на долю молодых людей в возрасте от 15 до 24 лет приходился 31 процент новых случаев заражения вич по всему миру , и 57 процентов новых случаев заражения среди этой возрастной группы приходилось на девочек - подростков и молодых женщин [ 1 ].\n",
            "Predicted translation: in 2013 , young people aged 15 to 24 , 000 , 000 , 000 , 000 , 000 , and 57 percent of the new infections among the age of the\n",
            "\n",
            "\n",
            "Source: в целом , в рамках программы по молодежи и торговле рассматриваются вопросы о том , как адаптировать существующий инструментарий центра для целей удовлетворения потребностей молодежи и какие новые инструменты нужны для расширения занятости среди молодежи в мировом масштабе .\n",
            "Predicted translation: in general , the programme on youth and trade is considered as a priority to the existing centre for responding to the needs of young people and the new tools to increase\n",
            "\n",
            "\n",
            "Source: 43 . просит генерального секретаря представлять совету каждые три месяца доклад о ходе осуществления мандата моонсдрк , включая ее бригаду оперативного вмешательства , изложенного в настоящей резолюции , в том числе о следующих аспектах :\n",
            "Predicted translation: 43 . requests the secretary - general to submit the council for three months of the implementation of the mandate of the <unk> , including its full operational operational operational operational interference\n",
            "\n",
            "\n",
            "Source: без непрерывного поступления взносов целевой фонд не сможет оказывать помощь имеющим на нее право членам на протяжении 21 недели в год , в течение которых проходят заседания комиссии и ее подкомиссий .\n",
            "Predicted translation: without limited contributions to the trust fund , the fund will not assist member states for 21 weeks in the year , which shall be held by the commission and its legal\n",
            "\n",
            "\n",
            "Source: 6 . 4 программа оон - спайдер была учреждена для предоставления всеобщего доступа ко всем видам космической информации и услуг , связанных с предупреждением бедствий и преодолением их последствий , с тем чтобы содействовать осуществлению полного цикла мероприятий по предупреждению бедствий и преодолению их последствий .\n",
            "Predicted translation: 6 . 4 the un - <unk> programme was established to provide full access to all available space information and services related to disaster and mitigation and mitigation mitigation activities to facilitate\n",
            "\n",
            "\n",
            "Source: 12 . вновь обращается с просьбой к генеральному секретарю и другим административным руководителям участвующих организаций оказывать группе всестороннее содействие в своевременном получении всей запрашиваемой ею информации ;\n",
            "Predicted translation: 12 . again , the secretary - general and other administrative leaders of the governing group have been invited to provide comprehensive assistance to the working group to receive all information submitted\n",
            "\n",
            "\n",
            "Source: это выступление является безответственным , так как оно непосредственно бросает вызов основным принципам права вооруженных конфликтов и нормам международного гуманитарного права и подрывает международный мир и безопасность .\n",
            "Predicted translation: this is a series of irresponsible events , as it directly expresses the fundamental principle of the right of armed conflicts and the norms of international humanitarian law and the international peace\n",
            "\n",
            "\n",
            "Source: 14 . женевская конференция по разоружению является единственным надлежащим форумом для ведения переговоров относительно договора о запрещении производства расщепляющего материала для ядерного оружия или других ядерных взрывных устройств .\n",
            "Predicted translation: 14 . the tripartite conference on disarmament is the only appropriate forum to negotiate on the contract on the prohibition of the production of the <unk> material for nuclear weapons or other\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wLHAM4cmIht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}